{"cells":[{"cell_type":"markdown","id":"b2bc15cf","metadata":{"id":"b2bc15cf"},"source":["# GENERADOR DE GLOSAS EN LSE A PARTIR DE TEXTO\n","\n","**Celia Botella López**"]},{"cell_type":"markdown","source":["## 0. PREREQUISITOS"],"metadata":{"id":"7zL5LJGN2e_x"},"id":"7zL5LJGN2e_x"},{"cell_type":"code","execution_count":null,"id":"c66f1c69","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c66f1c69","outputId":"88d46fb6-f6b9-4001-aaec-dff429917f1e","executionInfo":{"status":"ok","timestamp":1684839211303,"user_tz":-120,"elapsed":8891,"user":{"displayName":"Celia Botella","userId":"06816699222030966497"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: stanza in /usr/local/lib/python3.10/dist-packages (1.5.0)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.22.4)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza) (1.16.0)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.1+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import math\n","!pip install stanza\n","import stanza"]},{"cell_type":"code","execution_count":null,"id":"34cc3276","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364,"referenced_widgets":["e604e8eddb904d47a5526fb00c7dc817","3fcf5cd3bf884ff7897de09d5dcfca21","0be9752fd44740208aca393281af69eb","7c67e08ed0ca4f8ea8671658a557cea1","c107638a82e64b49826691d5e5406de6","baf3199ceb85448eab4e6d1361348c92","afc3000310e349deae3263f17506a1be","e07690773e004740bfffc11ab5308a9b","39abac277d004dd3837efaf9c9fb8532","7bca825ac35d4b5cac7070ece9de3277","544c937575d5487bb5bbe7b0e07ddc40"]},"id":"34cc3276","executionInfo":{"status":"ok","timestamp":1684839212972,"user_tz":-120,"elapsed":1675,"user":{"displayName":"Celia Botella","userId":"06816699222030966497"}},"outputId":"359283a7-8c65-424b-dd91-17e6b61e0722"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e604e8eddb904d47a5526fb00c7dc817"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Loading these models for language: es (Spanish):\n","=======================\n","| Processor | Package |\n","-----------------------\n","| tokenize  | ancora  |\n","| mwt       | ancora  |\n","| pos       | ancora  |\n","| lemma     | ancora  |\n","=======================\n","\n","INFO:stanza:Using device: cpu\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: mwt\n","INFO:stanza:Loading: pos\n","INFO:stanza:Loading: lemma\n","INFO:stanza:Done loading processors!\n"]}],"source":["nlp = stanza.Pipeline(lang='es', processors='tokenize,mwt,pos,lemma')"]},{"cell_type":"markdown","id":"kST47BxPlHsi","metadata":{"id":"kST47BxPlHsi"},"source":["## 1. FUNCIÓN DE GENERACIÓN DE GLOSAS"]},{"cell_type":"markdown","id":"PPpJb6rolj7w","metadata":{"id":"PPpJb6rolj7w"},"source":["El generador que se implementa a continuación, transforma un texto escrito en español a su glosa en LSE. La función, denominada _`generatorText2Gloss()`_, recibe por parámetros:\n","* `input_text`: Secuencia de caracteres que forma el texto para el que se va a genera la glosa.\n","* `path_rules`: Ruta del fichero que contiene las reglas de transformación correspondientes a la LSE. Estas son las que se aplican a las frases para obtener la glosa.\n","* `path_corpus`: Ruta del fichero en el que se va a almacenar el corpus generado (pares de frases en español y glosa).\n","* `nlp`: Instancia de un pipeline de stanza.\n","* `max_len`: Longitud máxima que debe tener una frase para que sea transformada.\n","\n","En primer lugar, se invoca a la función _`prepareText(text)`_, que modifica el formato del texto (string) a una lista de frases, donde cada frase es un listado de palabras, y cada palabra una instancia de la clase `Word`.\n","\n","Seguidamente, se carga el conjunto de reglas de transformación almacenadas en el archivo (de tipo CSV) que recibe la función por parámetro. Para cada una de las frases que componen el texto, se aplican las reglas de transformación. Las reglas se aplican invocando a la fución _`applyRules(sentence, rules)`_, que espera por parámetro la frase y el listado de reglas. Esta función devuelve la misma frase con la información de las palabras actualizada: nueva posición que ocupa en la frase transformada y lema que representa su glosa.\n","\n","Una vez que se obtiene la frase transformada, se invoca a la función _`glossSentece(sentence)`_, para formatear la frase (representada como una lista) a su correspondiente glosa en string.\n","\n","Finalmente, se almacena en el fichero destino del corpus cada una de las frases del texto inicial junto a su resultado en glosas."]},{"cell_type":"code","execution_count":null,"id":"nGyiUnI3lF9c","metadata":{"id":"nGyiUnI3lF9c"},"outputs":[],"source":["def generatorText2Gloss(input_text, path_rules, path_corpus, nlp, max_len = 20):\n","    text = prepareText(input_text, nlp) ## Listado de frases\n","\n","    rules = pd.read_csv(path_rules, encoding='utf-8') ## Lectura de reglas\n","\n","    for sentence in text:\n","      if sentence != None:\n","        nwords = len(sentence)\n","        if nwords <= max_len:\n","          input_sentence = ' '.join([word.text for word in sentence]) ## Frase original\n","\n","          ## Generar la glosa de la frase\n","  #        print(\"FRASE ORIGINAL: \", input_sentence)\n","          new_sentence = applyRules(sentence, rules, nlp) ## Aplicación de reglas\n","          gloss_sentence = glossSentece(new_sentence) ## Frase glosada\n","  #        print(\"\\n\\nRESULTADO GLOSA: \", gloss_sentence)\n","\n","          ## Almacenamiento del resultado...\n","          insertCorpus(path_corpus, input_sentence, gloss_sentence)\n","\n","  return \"\""]},{"cell_type":"markdown","id":"tDUjapT715cB","metadata":{"id":"tDUjapT715cB"},"source":["En definitiva, podemos diferenciar cuatro pasos principales: preparación de datos de entrada, aplicación de reglas, generación de glosa e inserción del resultado en el corpus. Para cada uno de ellos, se ha implementado una función."]},{"cell_type":"markdown","id":"theYFADQ3OBp","metadata":{"id":"theYFADQ3OBp"},"source":["### 1.1. PREPARACIÓN DE DATOS DE ENTRADA"]},{"cell_type":"markdown","id":"Y7ItuTfkzn-V","metadata":{"id":"Y7ItuTfkzn-V"},"source":["La primera función _`prepareText(str_text, nlp)`_ recibe como entrada texto en formato string y devuelve el texto como un listado de frases, que a su vez son listas de palabras (instancias de la clase _`Word`_).\n","\n","Para ello, se invoca al pipeline de la biblioteca *Stanza*, que separa el texto en frases por los signos de puntuación, tokeniza las frases en palabras, obtiene el lema de las palabras y analiza sintácticamente la frase, devolviendo información sobre la categoría gramatical cada una de las palabras que componen la oración.\n","\n","Por cada frase del texto, se iteran sus palabras y se crea una instancia de la clase `Word` para cada una de ellas. La clase `Word` tiene los siguientes atributos: identificador (`id`), palabra textual (`text`), lema de la palabra (`lemma`), categoria gramatical universal (`upos`), categoría gramatical específica (`xpos`) y posición (`pos`) dentro de la oración a la que pertenece.\n","\n","Las frases se define como una lista de instancias de la clase _`Word`_. Y el texto que devuelve la función será un listado de frases, o lo que es lo mismo, un listado de listas de palabras."]},{"cell_type":"code","execution_count":null,"id":"58a06fa3","metadata":{"id":"58a06fa3"},"outputs":[],"source":["class Word:\n","    def __init__(self, ident, text, lemma, upos, xpos, pos):\n","        self.id = ident\n","        self.text = text\n","        self.upper_text = str(text.upper())\n","        self.lemma = str(lemma.upper())\n","        self.upos = str(upos.lower()) if upos != None else \"\"\n","        self.xpos = str(xpos.lower()) if xpos != None else \"\"\n","        self.pos = pos\n","\n","\n","def prepareText(str_text, nlp):\n","    doc = nlp(str_text) ## Separa el texto en frases con palabras y sus caracteristicas\n","    text = []  ## Texto: listado de frases\n","\n","    ## Iterar las frases extraidas\n","    for sent in doc.sentences:\n","        sentence = [] ## Frase: listado de palabras\n","        for word in sent.words:\n","            sentence.append(Word(word.id, word.text, word.lemma, word.upos, word.xpos, word.id-1))\n","        text.append(sentence) ## Insertar frase formateada en el texto\n","\n","    return text"]},{"cell_type":"markdown","id":"TL0GNtx545W_","metadata":{"id":"TL0GNtx545W_"},"source":["### 1.2. APLICACIÓN DE REGLAS"]},{"cell_type":"markdown","id":"2fcf3854","metadata":{"id":"2fcf3854"},"source":["La función _`applyRule()`_ se encarga de aplicar las reglas a una frase. Recibe por parámetros:\n","* *sentence*: Listado de instancias de palabras.\n","* *rules*: Conjunto de reglas que se van a aplicar para transformar la frase.\n","* `nlp`: Instancia de un pipeline de stanza.\n","\n","Las reglas se intentarán aplicar de una en una. Por tanto, comenzamos recorriéndolas. Cada regla tiene una estructura de entrada y una estructura de salida. Si se cumple la estructura de entrada, se transforma según la estructura de salida. Para trabajar mejor con las reglas, se modifica el formato en el que se representan las estructuras, de string a diccionario, con la función _`ruleAsDictionary(rule)`_ definifida.\n","\n","Para encontrar qué palabras de la frase cumplen la estructura de entrada de una regla, invocamos a la función _`checkRule()`_. Dicha función devuelve las palabras que coinciden con el estructura de entrada de la regla. Puede ser que encuentre más de una solución (o coincidencia de estructura de entrada) en la frase, si la estructura se repite para varios conjuntos de palabras distintos.\n","\n","Una vez encontrados los conjuntos de palabras que cumplen la entrada de una regla, hay cuatro opciones:\n","* Eliminar las palabras de entrada (input) que no se encuentran en la estructura de salida (output). Esto se hace modificando el valor de la posición de la palabra a -1.\n","* Insertar las palabras que no se encuentran en la estructura de entrada (input), pero sí están en la de salida (output). Las nuevas palabras son las que tienen el identificador a 0 en la estructura de salida. Al insertar la palabra, hay que tener en cuenta la posición en la que se encuentra dentro de la estructura de salida. Además, en estos casos, la descripción de la palabra en la estructura de salida será el lema que se utilice para el glosado de la palabra.\n","* Ordenar las palabras que se encuentran tanto en la estructura de entrada (input) como en la de salida (output), pero que en la salida están situadas en otra posición distinta a la de entrada. Para ello, se actualiza el valor del atributo de posición de cada palabra según se sitúen en la estructura de salida.\n","* Actualizar el lema de las palabras que se encuentran tanto en la estructura de entrada (input) como en la de salida (output), pero su descripción en la estructura de entrada es distinta a la que tiene en la de salida. En este caso, se modifica el lema de la palabra asociando la nueva descripción, según se indica en la estructura de salida.\n","\n","Después de aplicar todas las reglas de transformación a la frase, se devuelve la misma frase de entrada pero con las posiciones de las palabras y sus lemas actualizados. Esta es la frase transformada que se utiliza para los pasos posteriores de generación de glosas e inserción en el corpus.\n"]},{"cell_type":"code","execution_count":null,"id":"a42659a1","metadata":{"id":"a42659a1"},"outputs":[],"source":["def applyRules(sentence, rules, nlp):\n","    nwords = len(sentence) ## Numero de palabras en la frase\n","    pos = 1  ## Posición actual\n","    new_sentence = list(sentence) ## Frase transformada/actualizada\n","    exclusive_rules_applies = [] ## Reglas excluyentes aplicadas\n","\n","    ## Iterar reglas de transformación\n","    for id_rule, row in rules.iterrows():\n","\n","        ## Obtener la estructura de entrada y salida de la regla\n","        input_rule = ruleAsDictionary(row['input'])\n","        output_rule = ruleAsDictionary(row['output'])\n","        exclusive_rule = row['exclusive']\n","\n","\n","        ## Si la regla no es excluyente o no se ha aplicado otra que la excluya\n","        if exclusive_rule is None or not exclusive_rule in exclusive_rules_applies:\n","            ## Buscar las palabras de la frase que coinciden con la estructura de entrada\n","            new_sentence.sort(key=lambda x: x.pos)\n","            len_sentence = sum(word.pos>-1 for word in new_sentence)\n","            list_coincidences = checkRule(new_sentence, len_sentence, input_rule, 0, 1, [], [])\n","\n","            if len(list_coincidences)>0:\n","                if not exclusive_rule is None:\n","                    exclusive_rules_applies.append(exclusive_rule) ## Insertar como aplicada\n","\n","                for coincidence in list_coincidences:\n","#                    print(\"\\n\\nAPLICAR REGLA:\")\n","#                    print(\"Input Rule: \", input_rule)\n","#                    print(\"Output Rule: \", output_rule)\n","#                    print(\"Coincidencia: \", coincidence)\n","                    coincidence_flatten = [j for sub in coincidence for j in sub]\n","\n","                    ## Posicion del primer elemento que cumple con la regla\n","                    pos = next(word.pos for word in new_sentence if coincidence_flatten[0]==word.id)\n","\n","                    ## Identificadores de las ultimas palabras que no cumplen con la regla\n","                    pos_last = next(word.pos for word in new_sentence if coincidence_flatten[-1]==word.id)\n","                    ids_last = [word.id for word in new_sentence if pos_last<word.pos]\n","\n","                    ## Eliminar palabras del input rule que no estan en el output, poniendo posición a -1\n","                    ids_input_delete = list(iw for iw in list(input_rule) if iw not in list(output_rule))\n","                    for id_input_delete in ids_input_delete:\n","                        for id_delete in coincidence[id_input_delete-1]:\n","                          ## Busqueda de palabra con id a eliminar\n","                            for x in new_sentence:\n","                                if x.id == id_delete:\n","                                    x.pos = -1\n","\n","                    ## Iterar las palabras en el output rule\n","                    for output_id in output_rule:\n","                        ## Añadir una nueva palabra, si el id en el output es 0 (no está en el input)\n","                        if output_id == 0:\n","                            nwords += 1\n","                            new_word_nlp = nlp(output_rule[output_id]).sentences[0].words[0]\n","                            new_word = Word(nwords, output_rule[output_id], output_rule[output_id], new_word_nlp.upos, new_word_nlp.xpos, pos)\n","                            new_sentence.append(new_word) ## Insertar palabra\n","                            pos += 1 ## Incrementar posición actual\n","\n","                        ## Actualizar las palabras del output que estan en el input\n","                        elif output_id in list(input_rule) :\n","\n","                            ## Descripción la palabra actual del input y output rule\n","                            input_word = input_rule[output_id]\n","                            output_word = output_rule[output_id]\n","\n","                            for id_word in coincidence[output_id-1]:\n","                                ## Actualizar la posición de la palabra con la posición actual\n","                                current_word = next(x for x in new_sentence if x.id == id_word)\n","                                current_word.pos = pos\n","                                pos += 1 ## Incrementar posición actual\n","\n","                                ## Si la descripcion del input y el output no coinciden\n","                                if(input_word != output_word):\n","                                    replace_word = output_word.replace(input_word, current_word.lemma.upper())\n","                                    current_word.lemma = replace_word   ## Modificar lema de la palabra\n","\n","                    #Actualizar posiciones del resto de palabras de la frase\n","                    for word in new_sentence:\n","                        if word.id in ids_last:\n","                            word.pos = pos\n","                            pos += 1 ## Incrementar posición actual\n","                    new_sentence.sort(key=lambda x: x.pos)\n","\n","                ## Imprimir la frase transformada tras aplicar una regla\n","#                print(glossSentece(new_sentence))\n","\n","    return new_sentence\n","\n","\n","## Función que transforma el formato de una regla: de string a diccionario\n","## Las claves del diccionario sera la posición de las palabras (enteros)\n","## Los valores del diccionario sera la representación de las palabras (string)\n","def ruleAsDictionary(rule):\n","    dic_rule = {}\n","    ## Si la regla es nula, se devuelve un dict vacío\n","    if rule!=rule:\n","        return {}\n","\n","    formatted_rule = rule.strip() ## Eliminar espacios del principio y fin\n","    formatted_rule = \" \".join(formatted_rule.split()) ## Reemplazar multiples espacios por uno\n","\n","    ## Separar el string por los delimitadores indicados\n","    list_rule = formatted_rule.split(\" \")\n","    for elem in list_rule:\n","        ident, desc = elem.split(\"_\", 1)\n","        dic_rule[int(ident)] = desc\n","\n","    return dic_rule"]},{"cell_type":"markdown","id":"36dcbc30","metadata":{"id":"36dcbc30"},"source":["La función _`checkRule()`_ es la que comprueba si una frase cumple una regla concreta. Se trata de una función de búsqueda recursiva. Recibe por parámetros:\n","* *sentence*: Frase como listado de palabras.\n","* *len_sentence*: Longitud de la frase.\n","* *rule*: Estructura de entrada de la regla que se va a comprobar si se cumple para la frase de entrada.\n","* *current_pos_word*: Posición de la palabra que se está comprobando actualmente.\n","* *current_pos_rule*: Posición de la parte de la regla que se está comprobando actualmente.\n","* *current_id*: Identificador de la palabra que se está comprobando actualmente.\n","* *current_solution*: Solución parcial encontrada hasta el momento (no definitiva). La solución es un listado de palabras.\n","* *solutions*: Listado con las soluciones definitivas encontradas. Cada solucion es un listado de palabras que cumplen con la regla.\n","\n","Esta función, recorre las palabras de la frase de forma recursiva, comprobando si la posición y descripción de esa palabra coincide con la descripción que tiene la estructura de entrada de la regla (input rule) en esa posición. Al comprobar si una palabra cumple con la descripción, pueden ocurrir dos cosas:\n","* Que la descripción del input rule esté en minúscula. Se comprueba si el valor del campo descripción coincide con el del atributo upos o xpos de la palabra.\n","* Que la descripción del input rule esté en mayúscula. Se comprueba si el valor del campo descripción coincide con el del atributo texto o lema de la palabra.\n","\n","Cuando en la regla aparezca una descripción con valor *, significará que cualquier palabra es válida, por lo que se insertan en la solución todas las palabras hasta encontrar otra que coincida con la siguiente descripción que aparece en la regla.\n","\n","Las palabras que cumplan con la descripción, se insertan en el listado *current_solution* y se invoca a la función de nuevo para comprobar si la siguiente palabra coincide con la siguiente descripción de la regla. Una vez que se recorran todas las posiciones de la regla cumpliendose, la solución será definitiva y se almacena en el listado *solutions*. Si por el contrario, una palabra no cumple con la descripción de la regla, se descarta la solución parcial y se empieza a buscar una nueva solución.\n","\n","Se siguen buscando soluciones hasta que se recorran todas las palabras de la frase.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"9dedabc4","metadata":{"id":"9dedabc4"},"outputs":[],"source":["def checkRule(sentence, len_sentence, rule, current_pos_word=0, current_pos_rule=1, current_solution=[], solutions=[]):\n","    ## Si la longitud de la solución es la misma que la de la regla,\n","    ## se ha encontrado una solución completa\n","    if(len(current_solution) >= len(rule) and current_pos_rule > len(rule)):\n","        solutions.append(current_solution) ## Insertar la solución actual al listado de soluciones definitivas\n","        current_solution = [] ## Reiniciar la solucion actual\n","        current_pos_rule = 1 ## Reiniciar posicion\n","\n","    ## Si la palabra actual es la última, FIN DE LA RECURSIVIDAD\n","    if(current_pos_word == len_sentence):\n","        return solutions ## Devolver las soluciones encontradas\n","\n","    current_word = next((w for w in sentence if w.pos == current_pos_word),None)\n","\n","    if len(current_solution) < (current_pos_rule):\n","        current_solution.append([])\n","\n","    if(current_word == None):\n","        current_solution = []\n","        current_pos_rule = 1\n","    ## Comprobar si la palabra actual de la frase coincide con\n","    ## la descripción de la palabra actual de la regla\n","    elif(checkPartialRule(current_word, rule[current_pos_rule])):\n","        current_solution[current_pos_rule-1].append(current_word.id)\n","        current_pos_rule+=1\n","    elif rule[current_pos_rule] == '*':\n","        if(current_pos_rule+1 in rule.keys() and checkPartialRule(current_word, rule[current_pos_rule+1])):\n","            current_solution.append([current_word.id])\n","            current_pos_rule+=2\n","        else:\n","            current_solution[current_pos_rule-1].append(current_word.id)\n","\n","        if(current_pos_word+1 == len_sentence):\n","            #Descartar la ultima parte de la regla si es *\n","            if(current_pos_rule == len(rule.keys()) and rule[current_pos_rule] == '*'):\n","                current_solution.append([])\n","\n","            current_pos_rule+=1\n","    else:\n","        current_solution = []\n","        current_pos_rule = 1\n","\n","    ## LLAMADA RECURSIVA: Comprobar si la siguiente palabra cumple\n","    return checkRule(sentence, len_sentence, rule, current_pos_word+1, current_pos_rule, current_solution, solutions)"]},{"cell_type":"code","execution_count":null,"id":"49c4c9ba","metadata":{"id":"49c4c9ba"},"outputs":[],"source":["## Se comprueba si el valor de rule está en mayúscula y coincide con lemma\n","def isLemma(lemma, rule):\n","    return (rule.isupper() and (lemma == rule))\n","\n","## Se comprueba si el valor de rule está en minúscula y coincide con upos o xpos\n","def isUPOS(upos, rule):\n","    return rule.islower() and (upos == rule)\n","\n","def isXPOS(xpos, rule):\n","    if rule.islower() and (len(xpos) == len(rule)):\n","        arr_xpos = np.array(list(xpos))\n","        arr_rule = np.array(list(rule))\n","\n","        zero_pos = np.where(arr_rule == '0') ## Posiciones con un 0\n","        arr_xpos[zero_pos] = '0' ## Sustituir posiciones por 0\n","\n","        return np.array_equal(arr_xpos, arr_rule)\n","\n","    return False\n","\n","## Función que comprueba si una palabra coincide con la descripción de la regla\n","def checkPartialRule(word, rule):\n","    return (isLemma(word.lemma, rule) or isLemma(word.upper_text, rule) or isUPOS(word.upos, rule) or isXPOS(word.xpos, rule))"]},{"cell_type":"markdown","id":"GpdhbEHg3Xyx","metadata":{"id":"GpdhbEHg3Xyx"},"source":["### 1.3. GENERACIÓN DE GLOSAS"]},{"cell_type":"markdown","id":"2dCnKn5x3jDg","metadata":{"id":"2dCnKn5x3jDg"},"source":["La función _`glossSentece(sentence)`_, recibe una frase como lista de palabras (instancias de la clase `Word`). Se encarga de devolver un string con la glosa correspondiente a la frase de entrada. Para ello, se iteran las palabras de la frase y se concatena el lema de cada una en el orden que indica su atributo de posición (`pos`)."]},{"cell_type":"code","execution_count":null,"id":"kQ0w2DR_zQBH","metadata":{"id":"kQ0w2DR_zQBH"},"outputs":[],"source":["def glossSentece(sentence):\n","    result = \"\"\n","    ## Iterar posiciones de la frase\n","    for pos in range(0, len(sentence)):\n","        current_word = next( (w for w in sentence if w.pos == pos), None) ## Busqueda de palabra en la posicion actual\n","        if current_word != None:\n","            result += current_word.lemma + \" \" ## Lema de la palabra en la posicion actual\n","    return result"]},{"cell_type":"markdown","id":"6HyPfpQo5LnR","metadata":{"id":"6HyPfpQo5LnR"},"source":["### 1.4. INSERCIÓN EN EL CORPUS"]},{"cell_type":"markdown","source":["La función _`insertCorpus()`_ inserta nuevos pares de frases (texto en español y su correspondiente glosa) en un fichero que contiene el corpus de datos. Recibe por parámetros:\n","* `path_corpus`. La ruta dónde se localiza el fichero con el corpus.\n","* `input_sentence`. Frase original en español (como string).\n","* `gloss_sentence.` Glosa generada en LSE (como string)."],"metadata":{"id":"GG31j7I5A-6r"},"id":"GG31j7I5A-6r"},{"cell_type":"code","execution_count":null,"id":"Gs4LxKkW5K-E","metadata":{"id":"Gs4LxKkW5K-E"},"outputs":[],"source":["def insertCorpus(path_corpus, input_sentence, gloss_sentence):\n","    df = pd.DataFrame({'sentence': [str(input_sentence)], 'gloss': [str(gloss_sentence)]})\n","    df.to_csv(path_corpus, mode='a', index=False, header=False)"]},{"cell_type":"markdown","id":"b2b4615d","metadata":{"id":"b2b4615d"},"source":["## 2. PRUEBAS DE VALIDACIÓN DEL ALGORITMO"]},{"cell_type":"markdown","source":["Una vez implementado el algoritmo de transformación a glosas, se debe establecer un método de validación que verifique que se aplican las reglas de manera correcta y devuelve el resultado en glosas esperado."],"metadata":{"id":"Rh20jJCP9M5w"},"id":"Rh20jJCP9M5w"},{"cell_type":"code","execution_count":null,"id":"vLtwBFXpnIwK","metadata":{"id":"vLtwBFXpnIwK"},"outputs":[],"source":["## Si se está utilizando como entorno de trabajo Google Colab, hay que ejecutar esta celda\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/My Drive/LSEGloss2SpanishText/"]},{"cell_type":"markdown","source":["Para ello, se implementa la función `_test()_`, que recibe los siguientes parámetros:\n","* `path_sentences`. Ruta en la que se encuentra el corpus de pares de frases (español y glosa) con el que llevar a cabo las pruebas.\n","* `path_rules`: Ruta del fichero que contiene las reglas de transformación correspondientes a la LSE.\n","* `path_corpus`: Ruta del fichero en el que se va a almacenar el corpus generado (pares de frases en español y glosa).\n","* `nlp`: Instancia de pipeline de stanza.\n","\n","Primero, se carga un conjunto de pares de frases en español y glosa, desde la ruta que se indica por parámetro. Seguidamente, a cada una de las frases cargadas en español, se le aplica el algoritmo de generación de glosa (se invoca a la función _`generatorText2Gloss()`_) y se comprueba si la glosa generada coincide con la glosa cargada. Si es así, el algoritmo habrá pasado la prueba."],"metadata":{"id":"IaicgL3T9ffy"},"id":"IaicgL3T9ffy"},{"cell_type":"code","execution_count":null,"id":"7cba2b9f","metadata":{"id":"7cba2b9f"},"outputs":[],"source":["def test(path_sentences, path_rules, path_corpus, nlp):\n","    test_sentences = pd.read_csv(path_sentences, encoding='utf-8')\n","\n","    total = len(test_sentences)\n","    passed = 0\n","    counter = 1\n","    for index, sentence in test_sentences.iterrows():\n","        gloss = generatorText2Gloss(sentence[\"Frase\"], path_rules, path_corpus, nlp)\n","        if gloss.strip() == sentence[\"Glosa\"].strip():\n","            print(\"\\nTest \", counter, \".... passed\")\n","            passed+=1\n","        else:\n","            print(\"Test \", counter, \".... no passed\")\n","        counter+=1\n","\n","        print(\"Frase original:\", sentence[\"Frase\"])\n","        print(\"Glosa generada:\", gloss)\n","\n","    print(\"\\nTotal: \", passed, \"/\", total)"]},{"cell_type":"code","execution_count":null,"id":"fcad9580","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"fcad9580","executionInfo":{"status":"ok","timestamp":1684839294445,"user_tz":-120,"elapsed":3460,"user":{"displayName":"Celia Botella","userId":"06816699222030966497"}},"outputId":"63fc3ea5-2058-4ff8-c9a6-45724873a932"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test  1 .... passed\n","Frase original: Pepe compró un coche a Pepa.\n","Glosa generada: PASADO PEPE-NP COCHE COMPRAR PEPA-NP \n","\n","Test  2 .... passed\n","Frase original: Llegaremos mañana al lugar previsto.\n","Glosa generada: MAÑANA NOSOTROS LLEGAR LUGAR PREVISTO \n","\n","Test  3 .... passed\n","Frase original: Cervantes escribió el Quijote\n","Glosa generada: PASADO CERVANTES-NP QUIJOTE-NP ESCRIBIR \n","\n","Test  4 .... passed\n","Frase original: Jesús lleva la camisa muy sucia.\n","Glosa generada: JESÚS-NP CAMISA SUCIO MUCHO LLEVAR \n","\n","Test  5 .... passed\n","Frase original: Rubén y Fernando no quieren ir al cine.\n","Glosa generada: RUBÉN-NP FERNANDO-NP IR QUERER NO CINE \n","\n","Test  6 .... passed\n","Frase original: Carlos le dio una carta certificada.\n","Glosa generada: PASADO CARLOS-NP CARTA CERTIFICADO DAR ÉL \n","\n","Test  7 .... passed\n","Frase original: La película es apta para menores\n","Glosa generada: PELÍCULA APTO MENOR \n","\n","Test  8 .... passed\n","Frase original: Informé a Gabriel de tu lesión.\n","Glosa generada: PASADO YO LESIÓN TU INFORMAR GABRIEL-NP \n","\n","Test  9 .... passed\n","Frase original: Daniel ha comprado una camiseta roja.\n","Glosa generada: DANIEL-NP CAMISETA ROJO COMPRAR \n","\n","Test  10 .... passed\n","Frase original: Encontré a Juanjo apenado.\n","Glosa generada: PASADO YO ENCONTRAR JUANJO-NP APENADO \n","\n","Test  11 .... passed\n","Frase original: Jaime contestó asustado en clase.\n","Glosa generada: PASADO JAIME-NP CONTESTAR ASUSTADO CLASE \n","\n","Test  12 .... passed\n","Frase original: Diego golpeó ayer las sillas.\n","Glosa generada: AYER DIEGO-NP SILLA-PL GOLPEAR \n","\n","Test  13 .... passed\n","Frase original: ¿Quién ha estado en París?\n","Glosa generada: PARÍS-NP QUIÉN \n","\n","Test  14 .... passed\n","Frase original: ¿A quién han dado el premio?\n","Glosa generada: PREMIO DAR QUIÉN \n","\n","Test  15 .... passed\n","Frase original: Este cuadro ha sido pintado por el magnífico artista.\n","Glosa generada: CUADRO ESTE PINTAR ARTISTA MAGNÍFICO \n","\n","Total:  15 / 15\n"]}],"source":["test(\"Corpus/corpus-test.csv\", \"Gloss Generator/rules.csv\", \"Corpus/corpus-test-generated.csv\", nlp)"]},{"cell_type":"markdown","id":"17035f48","metadata":{"id":"17035f48"},"source":["## 3. GENERACIÓN DEL DATASET"]},{"cell_type":"code","source":["!pip install datasets\n","from datasets import load_dataset\n","\n","## Carga del corpus de datos con frases en español.\n","dataset = load_dataset(\"PereLluis13/spanish_speech_text\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":625,"referenced_widgets":["aa55652c69a54483aa9996a3d4fd185b","6c31077ea824429ba67efe100316a99f","a78c9c273a544d118c289bff4a0fb3d4","f45e624be5484d9cb3b4e88b61d61c3b","1b948f40ac114497bdb8c4ba5c989b9b","02af32e1cf844fdcb408746b9648274b","419bd9891d4e484591131f2c2dad19bb","818c8e28e3154811adf535b7ed295a11","e0cdcd7d67064ac2bc894f135121a543","7c7d15bcf69c4dc6b5565eb86fbe7eaa","f6224cfbc7d742bca689fcf06b314e9a"]},"id":"HHjdvOFu6O9V","executionInfo":{"status":"ok","timestamp":1684841602953,"user_tz":-120,"elapsed":16750,"user":{"displayName":"Celia Botella","userId":"06816699222030966497"}},"outputId":"bf0efc2e-d9da-43a1-cd06-610fbdd0efb6"},"id":"HHjdvOFu6O9V","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/PereLluis13___parquet/PereLluis13--spanish_speech_text-0084bfe735abe854/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa55652c69a54483aa9996a3d4fd185b"}},"metadata":{}}]},{"cell_type":"markdown","source":["Finalmente, se crea el corpus sintético final invocando a la función _`generatorText2Gloss()`_ y pasándole por parámetro las frases en español que queremos transformar a glosa. En este caso, utilizaremos las frases que contiene el corpus Spanish Speech Text."],"metadata":{"id":"pT37kB8hDdgi"},"id":"pT37kB8hDdgi"},{"cell_type":"code","source":["for text in dataset[\"clean\"][\"sentence\"]:\n","    generatorText2Gloss(text, 'Gloss Generator/rules.csv', 'Corpus/corpus-spanish-gloss.csv', nlp)"],"metadata":{"id":"OYv-LPNWYmhs"},"id":"OYv-LPNWYmhs","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["7zL5LJGN2e_x","kST47BxPlHsi","17035f48"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e604e8eddb904d47a5526fb00c7dc817":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fcf5cd3bf884ff7897de09d5dcfca21","IPY_MODEL_0be9752fd44740208aca393281af69eb","IPY_MODEL_7c67e08ed0ca4f8ea8671658a557cea1"],"layout":"IPY_MODEL_c107638a82e64b49826691d5e5406de6"}},"3fcf5cd3bf884ff7897de09d5dcfca21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf3199ceb85448eab4e6d1361348c92","placeholder":"​","style":"IPY_MODEL_afc3000310e349deae3263f17506a1be","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "}},"0be9752fd44740208aca393281af69eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e07690773e004740bfffc11ab5308a9b","max":30101,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39abac277d004dd3837efaf9c9fb8532","value":30101}},"7c67e08ed0ca4f8ea8671658a557cea1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bca825ac35d4b5cac7070ece9de3277","placeholder":"​","style":"IPY_MODEL_544c937575d5487bb5bbe7b0e07ddc40","value":" 216k/? [00:00&lt;00:00, 2.20MB/s]"}},"c107638a82e64b49826691d5e5406de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf3199ceb85448eab4e6d1361348c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afc3000310e349deae3263f17506a1be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e07690773e004740bfffc11ab5308a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39abac277d004dd3837efaf9c9fb8532":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7bca825ac35d4b5cac7070ece9de3277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"544c937575d5487bb5bbe7b0e07ddc40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa55652c69a54483aa9996a3d4fd185b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c31077ea824429ba67efe100316a99f","IPY_MODEL_a78c9c273a544d118c289bff4a0fb3d4","IPY_MODEL_f45e624be5484d9cb3b4e88b61d61c3b"],"layout":"IPY_MODEL_1b948f40ac114497bdb8c4ba5c989b9b"}},"6c31077ea824429ba67efe100316a99f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02af32e1cf844fdcb408746b9648274b","placeholder":"​","style":"IPY_MODEL_419bd9891d4e484591131f2c2dad19bb","value":"100%"}},"a78c9c273a544d118c289bff4a0fb3d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_818c8e28e3154811adf535b7ed295a11","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0cdcd7d67064ac2bc894f135121a543","value":2}},"f45e624be5484d9cb3b4e88b61d61c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c7d15bcf69c4dc6b5565eb86fbe7eaa","placeholder":"​","style":"IPY_MODEL_f6224cfbc7d742bca689fcf06b314e9a","value":" 2/2 [00:00&lt;00:00, 16.12it/s]"}},"1b948f40ac114497bdb8c4ba5c989b9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02af32e1cf844fdcb408746b9648274b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"419bd9891d4e484591131f2c2dad19bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"818c8e28e3154811adf535b7ed295a11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0cdcd7d67064ac2bc894f135121a543":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c7d15bcf69c4dc6b5565eb86fbe7eaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6224cfbc7d742bca689fcf06b314e9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}